{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"kg_train.csv/kg_train.csv\",encoding='latin-1')\n",
    "\n",
    "import re\n",
    "def clean_text(text):\n",
    "    \n",
    "    # Remove all the special characters\n",
    "    processed_feature = re.sub(r'\\W', ' ', str(text))\n",
    "\n",
    "    # remove all single characters\n",
    "    processed_feature= re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_feature)\n",
    "    \n",
    "    # remove all single numbers, or all numbers attached to a string\n",
    "    processed_feature= re.sub(r'\\s*([0-9])+\\s*', ' ', processed_feature)\n",
    "    \n",
    "    # Remove all www's\n",
    "    processed_feature = re.sub(r'www', ' ',processed_feature)\n",
    "\n",
    "    # Remove single characters from the start\n",
    "    processed_feature = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_feature) \n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    processed_feature = re.sub(r'\\s+', ' ', processed_feature, flags=re.I)\n",
    "\n",
    "    # Removing prefixed 'b'\n",
    "    processed_feature = re.sub(r'^b\\s+', '', processed_feature)\n",
    "\n",
    "    # Converting to Lowercase\n",
    "    processed_feature = processed_feature.lower()\n",
    "\n",
    "    return processed_feature\n",
    "\n",
    "train_data.loc[:,'preprocessed_text'] = train_data['text'].apply(clean_text)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "data_ham  = train_data[train_data['label'] == 0].copy() #This saves the messages that are HAM\n",
    "data_spam = train_data[train_data['label'] == 1].copy() #This saves the messages that are SPAM\n",
    "\n",
    "words_data_ham  = data_ham['preprocessed_text'] #Series containing the strings that are HAM\n",
    "words_data_spam = data_spam['preprocessed_text'] #Series containing the strings that are SPAM\n",
    "\n",
    "\n",
    "list_ham_words = [] #Split all strings in words_data_ham and save them in word-vectors\n",
    "for sublist in words_data_ham:\n",
    "    for item in sublist.split():\n",
    "        list_ham_words.append(item)\n",
    "\n",
    "list_spam_words = [] #Split all strings in words_data_spam and save them in word-vectors\n",
    "for sublist in words_data_spam:\n",
    "    for item in sublist.split():\n",
    "        list_spam_words.append(item)\n",
    "        \n",
    "c_ham  = Counter(list_ham_words)\n",
    "c_spam = Counter(list_spam_words)\n",
    "\n",
    "#df_hamwords_top10  = pd.DataFrame(c_ham.most_common(10),  columns=['word', 'count']) #save the top10 most common words in list_ham_words\n",
    "#df_spamwords_top10 = pd.DataFrame(c_spam.most_common(10), columns=['word', 'count']) #save the top10 most common words in list_spam_words\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sub_data_train, sub_data_val, sub_label_train, sub_label_val = train_test_split(train_data, train_data[\"label\"], test_size=0.4, random_state=5)\n",
    "\n",
    "bow_transformer = CountVectorizer().fit(sub_data_train['preprocessed_text'])\n",
    "\n",
    "X_train = bow_transformer.transform(sub_data_train['preprocessed_text'])\n",
    "X_val  = bow_transformer.transform(sub_data_val['preprocessed_text'])\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "\n",
    "#Learn Classifier\n",
    "clf = MultinomialNB().fit(X_train, sub_label_train)\n",
    "#Predict Val data\n",
    "pred_val = clf.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(sub_label_val,pred_val)\n",
    "print(accuracy)\n",
    "confusion_matrix(sub_label_val, pred_val)\n",
    "\n",
    "data_test = pd.read_csv(\"kg_test.csv/kg_test.csv\",encoding='latin-1')\n",
    "X_test = bow_transformer.transform(data_test['text'].apply(clean_text))\n",
    "pred_text = clf.predict(X_test)\n",
    "submission_file = pd.DataFrame({'Id': test_data.index,'Category':pred_text})\n",
    "submission_file.to_csv('to_submit.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
