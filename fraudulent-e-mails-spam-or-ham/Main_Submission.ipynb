{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"kg_train.csv/kg_train.csv\",encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "!\"\\#\\$%\\&'\\(\\)\\*\\+,\\-\\./:;<=>\\?@\\[\\\\\\]\\^_`\\{\\|\\}\\~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "print(string.punctuation)\n",
    "print (re.escape(string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "from textblob import TextBlob\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "patterns = [\n",
    "re.compile(r'[^\\w\\d\\s\\:\\)\\(]'),\n",
    "re.compile(r'\\s+[a-zA-Z]\\s+'),\n",
    "#re.compile(r'\\s+\\d+[a-zA-Z]+|[a-zA-Z]+\\d+\\s+|\\s+[a-zA-Z]+\\d+[a-zA-Z]+\\s+'),\n",
    "re.compile(r'\\s*([0-9])+\\s*'),\n",
    "re.compile(r'\\^[a-zA-Z]\\s+')]\n",
    "\n",
    "regexHTML = re.compile(r'<[^>]*?>')\n",
    "\n",
    "wordnet_lemma  = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    \n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def lemmatize_text(doc):\n",
    "    list_words = []\n",
    "    for item in doc.split():\n",
    "        list_words.append(wordnet_lemma.lemmatize(item,get_wordnet_pos(item)))\n",
    "    return(' '.join(map(str, list_words)))\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    # remove all HTML tags\n",
    "    processed_feature = re.sub(regexHTML, ' ', str(text))\n",
    "    \n",
    "    # tags since comments can contain '>' characters\n",
    "    processed_feature = re.sub(r\"(?s)<!--(.*?)-->[\\n]?\", ' ', processed_feature)\n",
    "    \n",
    "    #Remove all the special characters except :, ) and (\n",
    "    processed_feature = re.sub(patterns[0], ' ', processed_feature)\n",
    "    \n",
    "    # remove numbers attached to strings and single numbers\n",
    "    processed_feature= re.sub(patterns[2], ' ', processed_feature)\n",
    "    \n",
    "    # remove all single characters\n",
    "    #processed_feature= re.sub(patterns[1], ' ', processed_feature)\n",
    "\n",
    "    # Remove single characters from the start\n",
    "    #processed_feature = re.sub(patterns[3], ' ', processed_feature) \n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    processed_feature = re.sub(r'\\s+', ' ', processed_feature, flags=re.I)\n",
    "\n",
    "    # Removing prefixed 'b'\n",
    "    processed_feature = re.sub(r'^b\\s+', '', processed_feature)\n",
    "    \n",
    "    ######### Correct spelling and grammar: Using Textblob\n",
    "    #blob = TextBlob(processed_feature)\n",
    "    #processed_feature = str(blob.correct())\n",
    "\n",
    "    # Converting to Lowercase\n",
    "    processed_feature = processed_feature.lower()\n",
    "    \n",
    "    return lemmatize_text(processed_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['processed_text'] = train_data['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mill cheryl d monday january 18 2010 2:26 pmh doug band justin cooper cheryl millsmills cheryl dre: glad you re therediane reynolds mmezvinskyjust leave the hospital really rough and sad mark paul and others do the lord plus 10 worki sent keen an email re no security troop just arrive so the hopefully they will be able to keepb doctor there tonight around the clock cdmsent: mon jan 18 14:22:08 : glad you re therepi give me periodic update about what you re see and do love to all'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(train_data['text'][2915])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4174, 52203)\n",
      "(1790, 52203)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5650                                                   ok\n",
       "213     the current revcon document include a paragrap...\n",
       "2084                                                  fyi\n",
       "4785                      sorry to confirm they be not in\n",
       "4314    from israel radioby shmuel tal prime minister ...\n",
       "                              ...                        \n",
       "3046                   we have italready work on schedule\n",
       "1725    abedin huma friday may 22 2009 4:48 pmcalls ca...\n",
       "4079    5 rider haggard close jo borg south africa con...\n",
       "2254    some cat and dogs:1 talk to denis about eu sum...\n",
       "2915    mill cheryl d monday january 18 2010 2:26 pmh ...\n",
       "Name: processed_text, Length: 4174, dtype: object"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sub_data_train, sub_data_val, sub_label_train, sub_label_val = train_test_split(train_data, train_data[\"label\"], test_size=0.3, random_state=5)\n",
    "\n",
    "bow_transformer = CountVectorizer().fit(sub_data_train['processed_text'])\n",
    "\n",
    "X_train = bow_transformer.transform(sub_data_train['processed_text'])\n",
    "X_val  = bow_transformer.transform(sub_data_val['processed_text'])\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "\n",
    "sub_data_train['processed_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9553072625698324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[939,  65],\n",
       "       [ 15, 771]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Learn Classifier\n",
    "clf = MultinomialNB().fit(X_train, sub_label_train)\n",
    "#Predict Val data\n",
    "pred_val = clf.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(sub_label_val,pred_val)\n",
    "print(accuracy)\n",
    "confusion_matrix(sub_label_val, pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"kg_test.csv/kg_test.csv\",encoding='latin-1')\n",
    "X_test = bow_transformer.transform(data_test['text'].apply(clean_text))\n",
    "pred_text = clf.predict(X_test)\n",
    "submission_file = pd.DataFrame({'Id': data_test.index,'Category':pred_text})\n",
    "submission_file.to_csv('to_submit.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIRST: Lemmatizing (DONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SECOND: Spelling and grammar correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIRD: Implement formula to compute efficiency-accuracy ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOURTH: Weird a's show up in dictionary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
