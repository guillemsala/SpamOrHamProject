{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"kg_train.csv/kg_train.csv\",encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(string.punctuation)\n",
    "specialchars = list(string.punctuation)\n",
    "print(specialchars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from spellchecker import SpellChecker\n",
    "from textblob import TextBlob\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "patterns = [\n",
    "re.compile(r'\\W'),\n",
    "re.compile(r'\\s+[a-zA-Z]\\s+'),\n",
    "re.compile(r'\\s*([0-9])+\\s*'),\n",
    "re.compile(r'\\^[a-zA-Z]\\s+'),\n",
    "re.compile(r'\\s+'),\n",
    "re.compile(r'^b\\s+')]\n",
    "\n",
    "wordnet_lemma  = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    \n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def lemmatize_text(doc):\n",
    "    list_words = []\n",
    "    for item in doc.split():\n",
    "        list_words.append(wordnet_lemma.lemmatize(item,get_wordnet_pos(item)))\n",
    "    return(' '.join(map(str, list_words)))\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    #Remove all the special characters\n",
    "    processed_feature = re.sub(patterns[0], ' ', str(text))\n",
    "\n",
    "    # remove all single characters\n",
    "    processed_feature= re.sub(patterns[1], ' ', processed_feature)\n",
    "    \n",
    "    # remove all single numbers, or all numbers attached to a string\n",
    "    processed_feature= re.sub(patterns[2], ' ', processed_feature)\n",
    "\n",
    "    # Remove single characters from the start\n",
    "    processed_feature = re.sub(patterns[3], ' ', processed_feature) \n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    processed_feature = re.sub(patterns[4], ' ', processed_feature, flags=re.I)\n",
    "\n",
    "    # Removing prefixed 'b'\n",
    "    processed_feature = re.sub(patterns[5], '', processed_feature)\n",
    "    \n",
    "    ######### Correct spelling and grammar: Using Textblob\n",
    "    #blob = TextBlob(processed_feature)\n",
    "    #processed_feature = str(blob.correct())\n",
    "\n",
    "    # Converting to Lowercase\n",
    "    processed_feature = processed_feature.lower()\n",
    "    \n",
    "    return lemmatize_text(processed_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['processed_text'] = train_data['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...</td>\n",
       "      <td>1</td>\n",
       "      <td>dear sir strictly private business proposal be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Will do.</td>\n",
       "      <td>0</td>\n",
       "      <td>will do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nora--Cheryl has emailed dozens of memos about...</td>\n",
       "      <td>0</td>\n",
       "      <td>nora cheryl have email dozen of memo about hai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dear Sir=2FMadam=2C I know that this proposal ...</td>\n",
       "      <td>1</td>\n",
       "      <td>dear sir fmadam c know that this proposal migh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fyi</td>\n",
       "      <td>0</td>\n",
       "      <td>fyi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5959</th>\n",
       "      <td>I talked to CDM about doing some strategy sess...</td>\n",
       "      <td>0</td>\n",
       "      <td>i talk to cdm about do some strategy session t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5960</th>\n",
       "      <td>Dear Sir/CEO,=20I am Mr.D S Ammer, the purchas...</td>\n",
       "      <td>1</td>\n",
       "      <td>dear sir ceo i be mr s ammer the purchasing di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5961</th>\n",
       "      <td>Faxing to you now.</td>\n",
       "      <td>0</td>\n",
       "      <td>fax to you now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5962</th>\n",
       "      <td>Goodday,I am Joseph vaye,the son of late Issac...</td>\n",
       "      <td>1</td>\n",
       "      <td>goodday be joseph vaye the son of late issac n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5963</th>\n",
       "      <td>Hello my dearMy name is Prince George Sanoussi...</td>\n",
       "      <td>1</td>\n",
       "      <td>hello my dearmy name be prince george sanoussi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5964 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label  \\\n",
       "0     DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...      1   \n",
       "1                                              Will do.      0   \n",
       "2     Nora--Cheryl has emailed dozens of memos about...      0   \n",
       "3     Dear Sir=2FMadam=2C I know that this proposal ...      1   \n",
       "4                                                   fyi      0   \n",
       "...                                                 ...    ...   \n",
       "5959  I talked to CDM about doing some strategy sess...      0   \n",
       "5960  Dear Sir/CEO,=20I am Mr.D S Ammer, the purchas...      1   \n",
       "5961                                 Faxing to you now.      0   \n",
       "5962  Goodday,I am Joseph vaye,the son of late Issac...      1   \n",
       "5963  Hello my dearMy name is Prince George Sanoussi...      1   \n",
       "\n",
       "                                         processed_text  \n",
       "0     dear sir strictly private business proposal be...  \n",
       "1                                               will do  \n",
       "2     nora cheryl have email dozen of memo about hai...  \n",
       "3     dear sir fmadam c know that this proposal migh...  \n",
       "4                                                   fyi  \n",
       "...                                                 ...  \n",
       "5959  i talk to cdm about do some strategy session t...  \n",
       "5960  dear sir ceo i be mr s ammer the purchasing di...  \n",
       "5961                                     fax to you now  \n",
       "5962  goodday be joseph vaye the son of late issac n...  \n",
       "5963  hello my dearmy name be prince george sanoussi...  \n",
       "\n",
       "[5964 rows x 3 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4771, 78655)\n",
      "(1193, 78655)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4159    http://www.quinnipiac.edu/x1284.xml?ReleaselD=...\n",
       "2426                         Dear Sir, It is my great ...\n",
       "2446    Yes - will call later tonite or am.Had b/fast ...\n",
       "1496    PLEASE,DO RECONFIRM TO THIS OFFICE ,AS A MATTE...\n",
       "3662    Mr.SAMUEL PETTERSBOA Bank of AfricaBurkina Fas...\n",
       "                              ...                        \n",
       "3046                We have itAlready working on schedule\n",
       "1725    Abedin Huma <AbedinHÃÂ©state.gov>Friday May 2...\n",
       "4079    5 RIDER HAGGARD CLOSE=2C JO=2C BORG SOUTH AFRI...\n",
       "2254    Some cats and dogs:1. Talked to Denis about EU...\n",
       "2915    Mills Cheryl D <MillsCD@state.gov>Monday Janua...\n",
       "Name: text, Length: 4771, dtype: object"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sub_data_train, sub_data_val, sub_label_train, sub_label_val = train_test_split(train_data, train_data[\"label\"], test_size=0.2, random_state=5)\n",
    "\n",
    "bow_transformer = CountVectorizer().fit(sub_data_train['processed_text'])\n",
    "\n",
    "X_train = bow_transformer.transform(sub_data_train['processed_text'])\n",
    "X_val  = bow_transformer.transform(sub_data_val['processed_text'])\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "\n",
    "sub_data_train['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9681475272422464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[641,  37],\n",
       "       [  1, 514]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Learn Classifier\n",
    "clf = MultinomialNB().fit(X_train, sub_label_train)\n",
    "#Predict Val data\n",
    "pred_val = clf.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(sub_label_val,pred_val)\n",
    "print(accuracy)\n",
    "confusion_matrix(sub_label_val, pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"kg_test.csv/kg_test.csv\",encoding='latin-1')\n",
    "X_test = bow_transformer.transform(data_test['text'].apply(clean_text))\n",
    "pred_text = clf.predict(X_test)\n",
    "submission_file = pd.DataFrame({'Id': data_test.index,'Category':pred_text})\n",
    "submission_file.to_csv('to_submit.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIRST: Lemmatizing (DONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SECOND: Spelling and grammar correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIRD: Implement formula to compute efficiency-accuracy ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOURTH: Weird a's show up in dictionary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
